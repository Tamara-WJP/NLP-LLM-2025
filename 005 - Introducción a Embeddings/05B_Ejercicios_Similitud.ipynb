{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "23026057",
      "metadata": {
        "id": "23026057"
      },
      "source": [
        "# Ejercicios embeddings de oraciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4a1e365e",
      "metadata": {
        "id": "4a1e365e",
        "outputId": "39b87a9b-7312-4d64-feb7-4ebbb46b8e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting es-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.8.0/es_core_news_md-3.8.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!pip install scikit-learn\n",
        "!python -m spacy download es_core_news_md"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b960b83e",
      "metadata": {
        "id": "b960b83e"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "Desarrolla una función que tome dos argumentos: una oración objetivo y una lista de oraciones. Esta función debe calcular y devolver la oración de la lista que es más similar a la oración objetivo, basándose en la medida de la similitud coseno. Además, la función también debe retornar el puntaje de similitud obtenido por esta oración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bc14d42f",
      "metadata": {
        "id": "bc14d42f"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Cargar el modelo de lenguaje en español\n",
        "nlp = spacy.load('es_core_news_md')\n",
        "\n",
        "def encontrar_frase_similar(frase_objetivo, lista_de_frases):\n",
        "    # Crear un embedding para la frase objetivo\n",
        "    objetivo_embedding = nlp(frase_objetivo)\n",
        "\n",
        "    mayor_similitud = -1\n",
        "    frase_similar = None\n",
        "\n",
        "    # Iterar sobre todas las frases en la lista\n",
        "    for frase in lista_de_frases:\n",
        "        # Crear un embedding para la frase actual\n",
        "        frase_embedding = nlp(frase)\n",
        "\n",
        "        # Calcular la similitud coseno entre la frase objetivo y la frase actual\n",
        "        similitud = objetivo_embedding.similarity(frase_embedding)\n",
        "\n",
        "        # Si la similitud es mayor que la similitud más alta encontrada hasta ahora,\n",
        "        # actualizamos la similitud más alta y la frase más similar\n",
        "        if similitud > mayor_similitud:\n",
        "            mayor_similitud = similitud\n",
        "            frase_similar = frase\n",
        "\n",
        "    # Devolver la frase más similar y su similitud con la frase objetivo\n",
        "    return frase_similar, mayor_similitud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e0de9564",
      "metadata": {
        "id": "e0de9564",
        "outputId": "3947debc-098b-4bbb-91c1-0b1f03289eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('amo el helado de vainilla', 0.9888834953308105)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "encontrar_frase_similar('amo el helado de chocolate', ['amo el helado de vainilla', 'amo la ensalada de pepino'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "440e631b",
      "metadata": {
        "id": "440e631b"
      },
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Desarrolla la misma funcion, pero esta vez utilizando TF-IDF en lugar de Spacy para crear los vectores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6eeb8f6f",
      "metadata": {
        "id": "6eeb8f6f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def encontrar_frase_similar_tfidf(frase_objetivo, lista_de_frases_input):\n",
        "    # Incluir la frase objetivo en la lista de frases\n",
        "    lista_de_frases = lista_de_frases_input.copy()\n",
        "    lista_de_frases.append(frase_objetivo)\n",
        "\n",
        "    # Crear el TfidfVectorizer y transformar la lista de frases\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(lista_de_frases)\n",
        "\n",
        "    # Calcular la similitud coseno entre la frase objetivo (la última en la matriz)\n",
        "    # y todas las demás frases\n",
        "    similitudes = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix)\n",
        "\n",
        "    # Obtener el índice de la frase con la mayor similitud (excluyendo la última)\n",
        "    indice_similar = similitudes.argsort()[0][-2]\n",
        "\n",
        "    # Normalizar el puntaje de similitud a que esté entre 0 y 1\n",
        "    puntaje_similar = similitudes[0, indice_similar]\n",
        "\n",
        "    # Devolver la frase más similar y su puntaje de similitud\n",
        "    return lista_de_frases[indice_similar], puntaje_similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "573760f2",
      "metadata": {
        "id": "573760f2",
        "outputId": "159bd2e0-b528-48f0-bc47-390d550be360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('amo el helado de vainilla', np.float64(0.6496702663128741))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "encontrar_frase_similar_tfidf('amo el helado de chocolate', ['amo el helado de vainilla', 'amo la ensalada de pepino'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64638f45",
      "metadata": {
        "id": "64638f45"
      },
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Prueba ambas funciones con el siguiente dataset. Encuentras una diferencia en el rendimiento? A qué se debe? Cuándo sería mejor utilizar una respecto a otra?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6c4275a0",
      "metadata": {
        "id": "6c4275a0"
      },
      "outputs": [],
      "source": [
        "oracion_objetivo = \"Me gusta mucho el fútbol, mi equipo favorito es River Plate.\"\n",
        "\n",
        "dataset = [\"A él también le gusta mucho el fútbol, siempre lo está viendo.\",\n",
        "            \"El deporte favorito de María es el baloncesto, y su equipo es River Plate.\",\n",
        "            \"El fútbol es un deporte muy popular en el mundo.\",\n",
        "            \"Nunca he entendido por qué a la gente le gusta tanto el fútbol.\",\n",
        "            \"El helado de vainilla es mi sabor favorito.\",\n",
        "            \"Estoy aprendiendo a tocar la guitarra.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "mRreVywu58Vi",
      "metadata": {
        "id": "mRreVywu58Vi",
        "outputId": "14a3a2f9-6ca2-48fc-af6c-992326396923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('El deporte favorito de María es el baloncesto, y su equipo es River Plate.',\n",
              " np.float64(0.48685930446809356))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "encontrar_frase_similar_tfidf(oracion_objetivo, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "HgrVYe7j5-y-",
      "metadata": {
        "id": "HgrVYe7j5-y-",
        "outputId": "1c8af9d6-6006-4258-f3c5-641bfe6cedfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('El helado de vainilla es mi sabor favorito.', 0.6684115529060364)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "encontrar_frase_similar(oracion_objetivo, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ekyivr7obt9",
      "source": [
        "# GUÍA DE ESTUDIO - EJERCICIOS DE SIMILITUD\n",
        "\n",
        "## Preguntas y Respuestas Clave\n",
        "\n",
        "### **Comparación de Enfoques**\n",
        "\n",
        "**P: ¿Cuál es la diferencia principal entre spaCy y TF-IDF para similitud de oraciones?**  \n",
        "R: spaCy usa embeddings pre-entrenados que capturan semántica global. TF-IDF solo considera frecuencia de palabras exactas sin contexto semántico.\n",
        "\n",
        "**P: ¿Por qué spaCy puede encontrar similitud entre sinónimos?**  \n",
        "R: Sus embeddings están entrenados para que palabras con significados similares tengan vectores cercanos, mientras que TF-IDF trata \"coche\" y \"auto\" como completamente diferentes.\n",
        "\n",
        "**P: ¿En qué casos TF-IDF podría superar a spaCy?**  \n",
        "R: Cuando necesitas similitud lexical exacta, tienes vocabulario muy específico del dominio, o cuando las palabras clave literales son más importantes que el significado.\n",
        "\n",
        "### **Implementación Técnica**\n",
        "\n",
        "**P: ¿Por qué en TF-IDF agregamos la oración objetivo a la lista?**  \n",
        "R: Para que el vectorizador aprenda el vocabulario completo y pueda comparar todas las oraciones en el mismo espacio vectorial.\n",
        "\n",
        "**P: ¿Qué hace `argsort()[0][-2]` en la función TF-IDF?**  \n",
        "R: Obtiene el índice del segundo valor más alto de similitud (excluye la oración objetivo que sería la más similar a sí misma).\n",
        "\n",
        "**P: ¿Cómo procesa spaCy una oración completa?**  \n",
        "R: Combina los embeddings de palabras individuales (típicamente promediando) para crear un vector representativo de toda la oración.\n",
        "\n",
        "### **Análisis de Rendimiento**\n",
        "\n",
        "**P: ¿Qué patrón observas en el dataset de fútbol entre ambos métodos?**  \n",
        "R: spaCy encuentra mejor similitud semántica profunda. TF-IDF se enfoca en palabras compartidas literalmente (\"fútbol\", \"River Plate\").\n",
        "\n",
        "**P: ¿Cuándo usarías cada método en una aplicación real?**  \n",
        "R: spaCy para chatbots, búsqueda semántica, recomendaciones. TF-IDF para búsqueda de documentos, keywords matching, clasificación por temas específicos.\n",
        "\n",
        "### **Casos de Uso Prácticos**\n",
        "\n",
        "**P: ¿Cómo mejorarías la función de spaCy para mayor precisión?**  \n",
        "R: Usar modelos más grandes (es_core_news_lg), preprocesar texto, considerar pesos por importancia de palabras, o usar embeddings especializados del dominio.\n",
        "\n",
        "**P: ¿Qué limitaciones tiene cada approach?**  \n",
        "R: spaCy: dependiente del modelo pre-entrenado, puede perder especificidad del dominio. TF-IDF: ignora semántica, sensible al vocabulario exacto.\n",
        "\n",
        "## Puntos Clave para Recordar\n",
        "\n",
        "1. **spaCy = semántica global** vs **TF-IDF = frecuencia local**\n",
        "2. **Embeddings capturan significado** más allá de palabras exactas\n",
        "3. **TF-IDF mejor para matching literal** y vocabulario específico\n",
        "4. **Preprocessing afecta ambos métodos** pero diferentemente\n",
        "5. **Elección depende del caso de uso** específico\n",
        "6. **Combinar ambos approaches** puede ser óptimo en algunos casos\n",
        "\n",
        "## Consideraciones Importantes\n",
        "\n",
        "- spaCy requiere modelos pre-descargados y más memoria\n",
        "- TF-IDF es más rápido y liviano pero menos \"inteligente\"\n",
        "- La calidad del modelo spaCy afecta directamente resultados\n",
        "- TF-IDF puede funcionar mejor con preprocesamiento agresivo\n",
        "- Ambos son sensibles a la longitud de las oraciones\n",
        "\n",
        "## Conexión con Próxima Clase\n",
        "\n",
        "Estas técnicas de similitud son la base para **aplicaciones avanzadas**: sistemas de recomendación, búsqueda semántica, y extracción de información estructurada de textos.\n",
        "\n",
        "---\n",
        "*Consejo: Prueba ambos métodos con tus propias oraciones en español argentino. ¿Cuál maneja mejor lunfardo y referencias culturales locales?*"
      ],
      "metadata": {
        "id": "ekyivr7obt9"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_humai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}